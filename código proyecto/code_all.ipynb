{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import os\n",
    "import pandas as pd\n",
    "from obp.dataset import OpenBanditDataset\n",
    "from obp.ope import OffPolicyEvaluation, InverseProbabilityWeighting as IPW\n",
    "from obp.policy import BernoulliTS\n",
    "from obp.ope import (\n",
    "    OffPolicyEvaluation, \n",
    "    RegressionModel,\n",
    "    DirectMethod,\n",
    "    InverseProbabilityWeighting,\n",
    "    DoublyRobust\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import time\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Versión automática"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explorar_clusters(n_clusters, particion):\n",
    "\n",
    "    # Importar dataset original desde una copia: 'men_copy.csv'\n",
    "    path = os.path.join(\"open_bandit_dataset\", \"random\", \"all\", \"all_copy.csv\")\n",
    "    dataset = pd.read_csv(path,  index_col=0) # por ahora solo se utilizan datos 'men', 'random'\n",
    "\n",
    "    print(\"Tamaño del dataset completo: \", dataset.shape)\n",
    "\n",
    "    full_dataset = dataset.copy()\n",
    "\n",
    "    # user_features = dataset[[\"user_feature_0\", \"user_feature_1\", \"user_feature_2\", \"user_feature_3\"]]\n",
    "    # user_features_encoded = pd.get_dummies(user_features, columns=[\"user_feature_0\", \"user_feature_1\", \"user_feature_2\", \"user_feature_3\"])\n",
    "\n",
    "    user_features_encoded =  dataset.drop(columns=[\"item_id\", \"position\", \"click\", \"propensity_score\", \"timestamp\", \"user_feature_0\", \"user_feature_1\", \"user_feature_2\", \"user_feature_3\"])\n",
    "\n",
    "    kmeans = KMeans(init=\"k-means++\", n_clusters=n_clusters, random_state=12345)\n",
    "    predict = kmeans.fit_predict(user_features_encoded)\n",
    "\n",
    "    full_dataset['clusters'] = predict\n",
    "\n",
    "    cluster_datasets = []\n",
    "    cluster_results = []\n",
    "    cluster_sizes = []\n",
    "    bandit_dataset = []\n",
    "    # Aplicar una mascara al dataset para filtrar por cluster\n",
    "    for i in range(n_clusters): \n",
    "        print(i)\n",
    "        cluster_datasets.append(full_dataset.loc[full_dataset['clusters'] == i])\n",
    "\n",
    "    # Iteracion principal para sobreescribir csv de OBP\n",
    "    for i in range(n_clusters):\n",
    "\n",
    "        ################# potencial problema ###############\n",
    "        path = os.path.join(\"open_bandit_dataset\", \"random\", \"all\", \"all.csv\")\n",
    "        dataset = cluster_datasets[i]\n",
    "        cluster_size = dataset.shape[0]\n",
    "\n",
    "        dataset.to_csv(path, index=False)\n",
    "        print(\"Tamaño del dataser de cluster \", i, \": \" , dataset.shape)\n",
    "        ####################################################\n",
    "\n",
    "        dataset = OpenBanditDataset(behavior_policy=\"random\", campaign=\"all\", data_path=\"open_bandit_dataset\", dataset_name=\"all.csv\")\n",
    "        bandit_feedback = dataset.obtain_batch_bandit_feedback()\n",
    "\n",
    "        bandit_dataset.append(dataset)\n",
    "        \n",
    "        ######### Aqui aplicar simulacion y estimacion sobre clusters ###########\n",
    "        evaluation_policy = BernoulliTS(\n",
    "            n_actions=dataset.n_actions, \n",
    "            len_list=dataset.len_list, \n",
    "            campaign=\"all\",\n",
    "            random_state=12345,\n",
    "            policy_name = \"random\"\n",
    "        )\n",
    "\n",
    "        regression_model = RegressionModel(\n",
    "            n_actions=dataset.n_actions,\n",
    "            len_list=dataset.len_list,\n",
    "            action_context=dataset.action_context,\n",
    "            base_model=LogisticRegression(max_iter=1000, random_state=12345),\n",
    "        )\n",
    "\n",
    "        estimated_rewards_by_reg_model = regression_model.fit_predict(\n",
    "            context=bandit_feedback[\"context\"],\n",
    "            action=bandit_feedback[\"action\"],\n",
    "            reward=bandit_feedback[\"reward\"],\n",
    "            position=bandit_feedback[\"position\"],\n",
    "            pscore=bandit_feedback[\"pscore\"],\n",
    "            n_folds=3, # use 3-fold cross-fitting\n",
    "            random_state=12345,\n",
    "        )\n",
    "        \n",
    "        action_dist = evaluation_policy.compute_batch_action_dist(\n",
    "            n_sim=100000, n_rounds=bandit_feedback[\"n_rounds\"],\n",
    "        )\n",
    "\n",
    "        # estimate the policy value of BernoulliTS based on its action choice probabilities\n",
    "    # it is possible to set multiple OPE estimators to the `ope_estimators` argument\n",
    "        ope = OffPolicyEvaluation(\n",
    "            bandit_feedback=bandit_feedback,\n",
    "            ope_estimators=[InverseProbabilityWeighting(), DirectMethod(), DoublyRobust()]\n",
    "        )\n",
    "        \n",
    "\n",
    "        # `summarize_off_policy_estimates` returns pandas dataframes including the OPE results\n",
    "        estimated_policy_value, estimated_interval = ope.summarize_off_policy_estimates(\n",
    "            action_dist=action_dist, \n",
    "            estimated_rewards_by_reg_model=estimated_rewards_by_reg_model,\n",
    "            n_bootstrap_samples=10000, # number of resampling performed in bootstrap sampling.\n",
    "            random_state=12345,\n",
    "        )\n",
    "\n",
    "        cluster_results.append(estimated_policy_value)\n",
    "        cluster_sizes.append(cluster_size)\n",
    "    return cluster_results, cluster_sizes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---------------------- Explorando con 2 cluster(s) -----------------------\n",
      "\n",
      "Tamaño del dataset completo:  (1374327, 89)\n",
      "0\n",
      "1\n",
      "Tamaño del dataser de cluster  0 :  (1372115, 90)\n",
      "Tamaño del dataser de cluster  1 :  (2212, 90)\n",
      "{2: [1372115, 2212]}\n",
      "\n",
      "---------------------- Explorando con 3 cluster(s) -----------------------\n",
      "\n",
      "Tamaño del dataset completo:  (1374327, 89)\n",
      "0\n",
      "1\n",
      "2\n",
      "Tamaño del dataser de cluster  0 :  (1367927, 90)\n",
      "Tamaño del dataser de cluster  1 :  (2212, 90)\n",
      "Tamaño del dataser de cluster  2 :  (4188, 90)\n",
      "{2: [1372115, 2212], 3: [1367927, 2212, 4188]}\n",
      "\n",
      "---------------------- Explorando con 4 cluster(s) -----------------------\n",
      "\n",
      "Tamaño del dataset completo:  (1374327, 89)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Tamaño del dataser de cluster  0 :  (1363520, 90)\n",
      "Tamaño del dataser de cluster  1 :  (2212, 90)\n",
      "Tamaño del dataser de cluster  2 :  (4185, 90)\n",
      "Tamaño del dataser de cluster  3 :  (4410, 90)\n",
      "{2: [1372115, 2212], 3: [1367927, 2212, 4188], 4: [1363520, 2212, 4185, 4410]}\n",
      "\n",
      "---------------------- Explorando con 5 cluster(s) -----------------------\n",
      "\n",
      "Tamaño del dataset completo:  (1374327, 89)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Tamaño del dataser de cluster  0 :  (1361198, 90)\n",
      "Tamaño del dataser de cluster  1 :  (2122, 90)\n",
      "Tamaño del dataser de cluster  2 :  (3960, 90)\n",
      "Tamaño del dataser de cluster  3 :  (4524, 90)\n",
      "Tamaño del dataser de cluster  4 :  (2523, 90)\n",
      "{2: [1372115, 2212], 3: [1367927, 2212, 4188], 4: [1363520, 2212, 4185, 4410], 5: [1361198, 2122, 3960, 4524, 2523]}\n",
      "\n",
      "---------------------- Explorando con 10 cluster(s) -----------------------\n",
      "\n",
      "Tamaño del dataset completo:  (1374327, 89)\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Tamaño del dataser de cluster  0 :  (1352883, 90)\n",
      "Tamaño del dataser de cluster  1 :  (2110, 90)\n",
      "Tamaño del dataser de cluster  2 :  (141, 90)\n",
      "Ejecución detenida en cluster_size:  10\n",
      "\n",
      "------------------------------ Resultados ------------------------------\n",
      "\n",
      "{2: [     estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.003450                         0.999629\n",
      "dm                 0.003479                         1.007811\n",
      "dr                 0.003451                         0.999714,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.014247                         0.984800\n",
      "dm                 0.012468                         0.861875\n",
      "dr                 0.012212                         0.844125], 3: [     estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.003438                         0.999667\n",
      "dm                 0.003467                         1.008044\n",
      "dr                 0.003438                         0.999691,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.014247                         0.984800\n",
      "dm                 0.012468                         0.861875\n",
      "dr                 0.012212                         0.844125,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.007356                         0.993806\n",
      "dm                 0.007247                         0.979088\n",
      "dr                 0.007575                         1.023333], 4: [     estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.003422                         0.999639\n",
      "dm                 0.003451                         1.008056\n",
      "dr                 0.003422                         0.999576,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.014247                         0.984800\n",
      "dm                 0.012468                         0.861875\n",
      "dr                 0.012212                         0.844125,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.007362                         0.993806\n",
      "dm                 0.007252                         0.979009\n",
      "dr                 0.007634                         1.030588,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.008417                         1.003265\n",
      "dm                 0.007791                         0.928629\n",
      "dr                 0.007809                         0.930798], 5: [     estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.003405                         0.999614\n",
      "dm                 0.003434                         1.008145\n",
      "dr                 0.003405                         0.999660,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.013467                         0.985434\n",
      "dm                 0.011175                         0.817714\n",
      "dr                 0.010817                         0.791495,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.007780                         0.993806\n",
      "dm                 0.007745                         0.989335\n",
      "dr                 0.007931                         1.013067,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.008415                         1.001768\n",
      "dm                 0.007708                         0.917601\n",
      "dr                 0.007763                         0.924223,      estimated_policy_value  relative_estimated_policy_value\n",
      "ipw                0.013513                         1.002729\n",
      "dm                 0.011446                         0.849355\n",
      "dr                 0.011443                         0.849130]}\n"
     ]
    }
   ],
   "source": [
    "cluster_sizes = [2, 3, 4, 5, 10, 15]\n",
    "\n",
    "cluster_results = {}       # resultados OPE\n",
    "cluster_size_results = {}  # tamanos de cada cluster evaluado\n",
    "\n",
    "for cluster_size in cluster_sizes: \n",
    "    print(f\"\\n---------------------- Explorando con {cluster_size} cluster(s) -----------------------\\n\")\n",
    "    try:\n",
    "\n",
    "        experiment_results, experiment_size_results = explorar_clusters(n_clusters=cluster_size, particion='all')\n",
    "        cluster_results[cluster_size] = experiment_results\n",
    "        cluster_size_results[cluster_size] = experiment_size_results\n",
    "        print(cluster_size_results)\n",
    "    except: \n",
    "        print(\"Ejecución detenida en cluster_size: \", cluster_size)\n",
    "        break\n",
    "print(f\"\\n------------------------------ Resultados ------------------------------\\n\")\n",
    "print(cluster_results)\n",
    "\n",
    "# Para guardar los resultados de estimadores\n",
    "with open('results_all_user_affinity.pkl', 'wb') as f:\n",
    "    pickle.dump(cluster_results, f)\n",
    "\n",
    "# Para guardar los tamaños de los clusters    \n",
    "with open('size_results_all_user_affinity.pkl', 'wb') as f: \n",
    "    pickle.dump(cluster_size_results, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
